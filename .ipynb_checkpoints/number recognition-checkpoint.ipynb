{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9bc912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 0.3731 - accuracy: 0.8972 - val_loss: 0.1711 - val_accuracy: 0.9524\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1464 - accuracy: 0.9575 - val_loss: 0.1292 - val_accuracy: 0.9621\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9693 - val_loss: 0.1119 - val_accuracy: 0.9658\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0775 - accuracy: 0.9770 - val_loss: 0.1050 - val_accuracy: 0.9682\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0613 - accuracy: 0.9820 - val_loss: 0.0947 - val_accuracy: 0.9719\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.9729\n",
      "Test accuracy: 97.29%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images.reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images.reshape(-1, 28 * 28) / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Build the Neural Network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eae41e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 156ms/step - loss: 0.2466 - val_loss: 0.1785\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1957 - val_loss: 0.1362\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1499 - val_loss: 0.1006\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1117 - val_loss: 0.0727\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0820 - val_loss: 0.0547\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0621 - val_loss: 0.0478\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0544 - val_loss: 0.0504\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0540 - val_loss: 0.0548\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0560 - val_loss: 0.0550\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0554 - val_loss: 0.0526\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0538 - val_loss: 0.0490\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0521 - val_loss: 0.0472\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0519 - val_loss: 0.0462\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0518 - val_loss: 0.0458\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0515 - val_loss: 0.0456\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0511 - val_loss: 0.0456\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0508 - val_loss: 0.0460\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0505 - val_loss: 0.0462\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0502 - val_loss: 0.0455\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0499 - val_loss: 0.0451\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0497 - val_loss: 0.0450\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0494 - val_loss: 0.0445\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0490 - val_loss: 0.0443\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0488 - val_loss: 0.0440\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0487 - val_loss: 0.0440\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0484 - val_loss: 0.0438\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0481 - val_loss: 0.0433\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0479 - val_loss: 0.0429\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0477 - val_loss: 0.0428\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0476 - val_loss: 0.0428\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0474 - val_loss: 0.0428\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0472 - val_loss: 0.0423\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0470 - val_loss: 0.0420\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0468 - val_loss: 0.0420\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0466 - val_loss: 0.0419\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0465 - val_loss: 0.0421\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0464 - val_loss: 0.0414\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0462 - val_loss: 0.0415\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0461 - val_loss: 0.0412\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0459 - val_loss: 0.0413\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0458 - val_loss: 0.0411\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0456 - val_loss: 0.0412\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0455 - val_loss: 0.0409\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0454 - val_loss: 0.0403\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0453 - val_loss: 0.0405\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0451 - val_loss: 0.0405\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0451 - val_loss: 0.0400\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0449 - val_loss: 0.0403\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0448 - val_loss: 0.0402\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0447 - val_loss: 0.0402\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0447 - val_loss: 0.0403\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0446 - val_loss: 0.0400\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0446 - val_loss: 0.0401\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0445 - val_loss: 0.0400\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0444 - val_loss: 0.0394\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0444 - val_loss: 0.0395\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0443 - val_loss: 0.0397\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0446 - val_loss: 0.0402\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0444 - val_loss: 0.0391\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0443 - val_loss: 0.0393\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0443 - val_loss: 0.0390\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0441 - val_loss: 0.0394\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0441 - val_loss: 0.0397\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0441 - val_loss: 0.0400\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0442 - val_loss: 0.0395\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0441 - val_loss: 0.0395\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0441 - val_loss: 0.0394\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0440 - val_loss: 0.0396\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0440 - val_loss: 0.0397\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0440 - val_loss: 0.0393\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0440 - val_loss: 0.0394\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0440 - val_loss: 0.0390\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0441 - val_loss: 0.0395\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0445 - val_loss: 0.0387\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0439 - val_loss: 0.0395\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0439 - val_loss: 0.0397\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0440 - val_loss: 0.0399\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0440 - val_loss: 0.0394\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0439 - val_loss: 0.0393\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0439 - val_loss: 0.0392\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0439 - val_loss: 0.0393\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0439 - val_loss: 0.0392\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0439 - val_loss: 0.0394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0439 - val_loss: 0.0394\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0439 - val_loss: 0.0395\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0440 - val_loss: 0.0399\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0444 - val_loss: 0.0402\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0438 - val_loss: 0.0388\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0440 - val_loss: 0.0386\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0440 - val_loss: 0.0390\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0439 - val_loss: 0.0394\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0442 - val_loss: 0.0402\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0439 - val_loss: 0.0395\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0438 - val_loss: 0.0389\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0440 - val_loss: 0.0390\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0441 - val_loss: 0.0395\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0438 - val_loss: 0.0391\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0440 - val_loss: 0.0387\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0439 - val_loss: 0.0394\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0439 - val_loss: 0.0395\n",
      "2/2 [==============================] - 1s 1ms/step\n",
      "R-squared score: -0.049950348141581946\n",
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (74) does not match length of index (76)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m predicted \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(predicted)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Add the sales predicted as a new column in the test dataframe\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msales_predicted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m predicted\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Save the test DataFrame with the sales predicted as a new CSV file\u001b[39;00m\n\u001b[0;32m     75\u001b[0m test\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msales_predicted_lstm.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4167\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4180\u001b[0m     ):\n\u001b[0;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (74) does not match length of index (76)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Step 1: Prepare the data\n",
    "data = pd.read_csv(\"sales_dataset.csv\")\n",
    "\n",
    "# Handle the missing values by justing assigning value 0\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Step 2: Feature Selection\n",
    "X = data[['TV']].values\n",
    "y = data['Sales'].values\n",
    "\n",
    "# Step 3: Normalize the data using Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 4: Prepare the data as sequences for LSTM\n",
    "sequence_length = 3  # Number of time steps to use for prediction\n",
    "X_seq, y_seq = [], []\n",
    "for i in range(len(X) - sequence_length):\n",
    "    X_seq.append(X[i:i + sequence_length])\n",
    "    y_seq.append(y[i + sequence_length])\n",
    "\n",
    "X_seq, y_seq = np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Step 5: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Step 7: Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 8: Evaluate the model with r-squared score\n",
    "y_pred = model.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(\"R-squared score:\", score)\n",
    "\n",
    "# Step 9: Read the test_set and preprocessing of test_setd\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test.fillna(0, inplace=True)\n",
    "\n",
    "# Extract features for prediction and normalize\n",
    "X_new = test[['TV']].values\n",
    "X_new = scaler.transform(X_new)\n",
    "\n",
    "# Reshape the data to fit the LSTM input shape\n",
    "X_new_seq = []\n",
    "for i in range(len(X_new) - sequence_length + 1):\n",
    "    X_new_seq.append(X_new[i:i + sequence_length])\n",
    "\n",
    "X_new_seq = np.array(X_new_seq)\n",
    "\n",
    "# Now make the predictions\n",
    "predicted = model.predict(X_new_seq)\n",
    "\n",
    "# Inverse transform the predicted sales to original scale\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "\n",
    "# Add the sales predicted as a new column in the test dataframe\n",
    "test['sales_predicted'] = predicted\n",
    "\n",
    "# Save the test DataFrame with the sales predicted as a new CSV file\n",
    "test.to_csv(\"sales_predicted_lstm.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bed6009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 159ms/step - loss: 0.2264 - val_loss: 0.1370\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1558 - val_loss: 0.0839\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1031 - val_loss: 0.0527\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0718 - val_loss: 0.0455\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0606 - val_loss: 0.0551\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0627 - val_loss: 0.0614\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0635 - val_loss: 0.0579\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0602 - val_loss: 0.0502\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0571 - val_loss: 0.0458\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0559 - val_loss: 0.0443\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0560 - val_loss: 0.0437\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0551 - val_loss: 0.0439\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0541 - val_loss: 0.0448\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0533 - val_loss: 0.0454\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0529 - val_loss: 0.0456\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0524 - val_loss: 0.0455\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0518 - val_loss: 0.0447\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0512 - val_loss: 0.0438\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0508 - val_loss: 0.0434\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0505 - val_loss: 0.0430\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0499 - val_loss: 0.0433\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0495 - val_loss: 0.0436\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0492 - val_loss: 0.0440\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0488 - val_loss: 0.0436\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0484 - val_loss: 0.0429\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0480 - val_loss: 0.0427\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0477 - val_loss: 0.0427\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0474 - val_loss: 0.0424\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0471 - val_loss: 0.0425\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0470 - val_loss: 0.0432\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0466 - val_loss: 0.0424\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0463 - val_loss: 0.0424\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0460 - val_loss: 0.0421\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0459 - val_loss: 0.0418\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0456 - val_loss: 0.0419\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0454 - val_loss: 0.0424\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0452 - val_loss: 0.0424\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0449 - val_loss: 0.0416\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0452 - val_loss: 0.0411\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0446 - val_loss: 0.0417\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0445 - val_loss: 0.0424\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0444 - val_loss: 0.0417\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0443 - val_loss: 0.0410\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0440 - val_loss: 0.0415\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0438 - val_loss: 0.0415\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0436 - val_loss: 0.0411\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0438 - val_loss: 0.0407\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0438 - val_loss: 0.0408\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0433 - val_loss: 0.0414\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0433 - val_loss: 0.0415\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0431 - val_loss: 0.0411\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0433 - val_loss: 0.0406\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0433 - val_loss: 0.0406\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0431 - val_loss: 0.0415\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0429 - val_loss: 0.0410\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0428 - val_loss: 0.0409\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0429 - val_loss: 0.0403\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0430 - val_loss: 0.0409\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0427 - val_loss: 0.0406\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0427 - val_loss: 0.0411\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0426 - val_loss: 0.0406\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0426 - val_loss: 0.0409\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0425 - val_loss: 0.0406\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0427 - val_loss: 0.0407\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0423 - val_loss: 0.0403\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0424 - val_loss: 0.0404\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0423 - val_loss: 0.0407\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0425 - val_loss: 0.0413\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0429 - val_loss: 0.0403\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0422 - val_loss: 0.0406\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0423 - val_loss: 0.0410\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0422 - val_loss: 0.0409\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0421 - val_loss: 0.0404\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0421 - val_loss: 0.0404\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0423 - val_loss: 0.0404\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0421 - val_loss: 0.0411\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0424 - val_loss: 0.0408\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0420 - val_loss: 0.0403\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0421 - val_loss: 0.0402\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0420 - val_loss: 0.0402\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0421 - val_loss: 0.0406\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0420 - val_loss: 0.0405\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0420 - val_loss: 0.0405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0419 - val_loss: 0.0405\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0422 - val_loss: 0.0406\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0421 - val_loss: 0.0402\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0419 - val_loss: 0.0402\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0422 - val_loss: 0.0402\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0417 - val_loss: 0.0409\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0420 - val_loss: 0.0410\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0418 - val_loss: 0.0402\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0419 - val_loss: 0.0400\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0426 - val_loss: 0.0407\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0418 - val_loss: 0.0403\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0418 - val_loss: 0.0401\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0421 - val_loss: 0.0405\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0417 - val_loss: 0.0402\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0418 - val_loss: 0.0401\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0422 - val_loss: 0.0409\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0417 - val_loss: 0.0403\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "R-squared score: -0.06956751763681379\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but MinMaxScaler is expecting 1 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Extract features for prediction and normalize\u001b[39;00m\n\u001b[0;32m     55\u001b[0m X_new \u001b[38;5;241m=\u001b[39m test[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRadio\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNewspaper\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m---> 56\u001b[0m X_new \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Reshape the data to fit the LSTM input shape\u001b[39;00m\n\u001b[0;32m     59\u001b[0m X_new_seq \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:508\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03m    Transformed data.\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    506\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 508\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    517\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:569\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 569\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:370\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 3 features, but MinMaxScaler is expecting 1 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Step 1: Prepare the data\n",
    "data = pd.read_csv(\"sales_dataset.csv\")\n",
    "\n",
    "# Handle the missing values by justing assigning value 0\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Step 2: Feature Selection\n",
    "X = data[['TV', 'Radio', 'Newspaper']].values\n",
    "y = data['Sales'].values\n",
    "\n",
    "# Step 3: Normalize the data using Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 4: Prepare the data as sequences for LSTM\n",
    "sequence_length = 3  # Number of time steps to use for prediction\n",
    "X_seq, y_seq = [], []\n",
    "for i in range(len(X) - sequence_length):\n",
    "    X_seq.append(X[i:i + sequence_length])\n",
    "    y_seq.append(y[i + sequence_length])\n",
    "\n",
    "X_seq, y_seq = np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Step 5: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Step 7: Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 8: Evaluate the model with r-squared score\n",
    "y_pred = model.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(\"R-squared score:\", score)\n",
    "\n",
    "# Step 9: Read the test_set and preprocessing of test_setd\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test.fillna(0, inplace=True)\n",
    "\n",
    "# Extract features for prediction and normalize\n",
    "X_new = test[['TV', 'Radio', 'Newspaper']].values\n",
    "X_new = scaler.transform(X_new)\n",
    "\n",
    "# Reshape the data to fit the LSTM input shape\n",
    "X_new_seq = []\n",
    "for i in range(len(X_new) - sequence_length + 1):\n",
    "    X_new_seq.append(X_new[i:i + sequence_length])\n",
    "\n",
    "X_new_seq = np.array(X_new_seq)\n",
    "\n",
    "# Now make the predictions\n",
    "predicted = model.predict(X_new_seq)\n",
    "\n",
    "# Inverse transform the predicted sales to original scale\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "\n",
    "# Add the sales predicted as a new column in the test dataframe\n",
    "test['sales_predicted'] = np.concatenate((np.zeros(sequence_length - 1), predicted.flatten()))\n",
    "\n",
    "# Save the test DataFrame with the sales predicted as a new CSV file\n",
    "test.to_csv(\"sales_predicted_lstm.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac715e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
